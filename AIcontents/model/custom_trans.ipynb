{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_trans.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGK2VA5raJimWlRSR6UaeV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seawavve/PeekABook/blob/main/model/custom_trans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogXZ7r5pHScS"
      },
      "source": [
        "setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arASAXysOPc2",
        "outputId": "52c14c91-d3e6-426c-de51-bffb71eb80c3"
      },
      "source": [
        "!pip3 install --quiet tensorflow\n",
        "!pip3 install --quiet tensorflow_text"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |                                | 10kB 27.9MB/s eta 0:00:01\r\u001b[K     |▏                               | 20kB 35.9MB/s eta 0:00:01\r\u001b[K     |▎                               | 30kB 27.0MB/s eta 0:00:01\r\u001b[K     |▍                               | 40kB 30.4MB/s eta 0:00:01\r\u001b[K     |▌                               | 51kB 27.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 61kB 22.1MB/s eta 0:00:01\r\u001b[K     |▊                               | 71kB 21.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 81kB 20.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 92kB 19.4MB/s eta 0:00:01\r\u001b[K     |█                               | 102kB 19.6MB/s eta 0:00:01\r\u001b[K     |█                               | 112kB 19.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 122kB 19.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 133kB 19.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 143kB 19.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 153kB 19.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 163kB 19.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 174kB 19.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 184kB 19.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 194kB 19.6MB/s eta 0:00:01\r\u001b[K     |██                              | 204kB 19.6MB/s eta 0:00:01\r\u001b[K     |██                              | 215kB 19.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 225kB 19.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 235kB 19.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 245kB 19.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 256kB 19.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 266kB 19.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 276kB 19.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 286kB 19.6MB/s eta 0:00:01\r\u001b[K     |██▉                             | 296kB 19.6MB/s eta 0:00:01\r\u001b[K     |███                             | 307kB 19.6MB/s eta 0:00:01\r\u001b[K     |███                             | 317kB 19.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 327kB 19.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 337kB 19.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 348kB 19.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 358kB 19.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 368kB 19.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 378kB 19.6MB/s eta 0:00:01\r\u001b[K     |███▊                            | 389kB 19.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 399kB 19.6MB/s eta 0:00:01\r\u001b[K     |████                            | 409kB 19.6MB/s eta 0:00:01\r\u001b[K     |████                            | 419kB 19.6MB/s eta 0:00:01\r\u001b[K     |████                            | 430kB 19.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 440kB 19.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 450kB 19.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 460kB 19.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 471kB 19.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 481kB 19.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 491kB 19.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 501kB 19.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 512kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 522kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 532kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 542kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 552kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 563kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 573kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 583kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 593kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 604kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 614kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 624kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 634kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 645kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 655kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 665kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 675kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 686kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 696kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 706kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 716kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 727kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 737kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 747kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 757kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 768kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 778kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 788kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 798kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 808kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 819kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 829kB 19.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 839kB 19.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 849kB 19.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 860kB 19.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 870kB 19.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 880kB 19.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 890kB 19.6MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 901kB 19.6MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 911kB 19.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 921kB 19.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 931kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 942kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 952kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 962kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 972kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 983kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 993kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 1.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 1.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 1.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 1.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 1.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 1.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 1.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 1.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 1.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 1.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 1.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 1.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 1.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 1.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 1.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 1.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 1.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 1.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 1.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 1.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 1.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 1.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 1.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 1.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 1.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 1.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 2.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 2.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 2.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 2.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 2.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 2.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 2.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 2.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 2.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 2.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 2.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 2.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 2.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 2.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 2.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 2.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 2.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 2.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 2.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 2.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 2.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 2.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 2.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 2.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 2.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 2.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 2.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 2.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 2.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 2.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 2.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 2.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 2.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 2.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 2.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 2.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 2.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 2.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 2.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 2.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 2.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 2.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 2.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 2.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 2.5MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 2.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 2.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 2.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 2.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 2.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.6MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 2.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 2.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.7MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 2.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.8MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.9MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 3.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 3.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 3.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 3.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 3.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 3.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 3.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 3.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.0MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 3.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 3.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 3.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 3.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 3.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 3.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 3.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 3.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.1MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 3.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 3.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 3.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 3.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 3.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 3.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 3.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 3.2MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 3.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 3.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 3.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 3.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 3.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 3.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 3.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 3.3MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.4MB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.4MB 19.6MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dBgxTAyGs3P"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline  \n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import pairwise\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text  # Imports TF ops for preprocessing.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUTQMsa3G5xu"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rr6DkdfG53O"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH7k7hWcN7k0"
      },
      "source": [
        "#@title Configure the model { run: \"auto\" }\n",
        "BERT_MODEL = \"https://tfhub.dev/google/experts/bert/wiki_books/sst2/2\" # @param {type: \"string\"} [\"https://tfhub.dev/google/experts/bert/wiki_books/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/mnli/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/qnli/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/qqp/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/squad2/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/sst2/2\",  \"https://tfhub.dev/google/experts/bert/pubmed/2\", \"https://tfhub.dev/google/experts/bert/pubmed/squad2/2\"]\n",
        "# Preprocessing must match the model, but all the above use the same.\n",
        "PREPROCESS_MODEL = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0PGmPJTHXsg"
      },
      "source": [
        "prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "2fquXTaUHlKd",
        "outputId": "92e57e0b-6738-41e2-9080-680760375245"
      },
      "source": [
        "vocab_size = 20000  # Only consider the top 20k words\n",
        "maxlen = 200  # Only consider the first 200 words of each x_data\n",
        "data=pd.read_csv('./Peterpan_emo3.csv')\n",
        "data=data.dropna(how='any')\n",
        "print(f'Dimensions: {data.shape}')\n",
        "data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensions: (1697, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentence</th>\n",
              "      <th>posNeg</th>\n",
              "      <th>posNeg3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Chapter 1 PETER BREAKS THROUGH</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>All children, except one, grow up. They soon k...</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Of course they lived at 14 [their house number...</td>\n",
              "      <td>0.279545</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The way Mr. Darling won her was this: the many...</td>\n",
              "      <td>0.483333</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Mr. Darling used to boast to Wendy that her mo...</td>\n",
              "      <td>0.148889</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1692</th>\n",
              "      <td>1692</td>\n",
              "      <td>“If only I could go with you,” Wendy sighed.</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1693</th>\n",
              "      <td>1693</td>\n",
              "      <td>“You see you can't fly,” said Jane.</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1694</th>\n",
              "      <td>1694</td>\n",
              "      <td>Of course in the end Wendy let them fly away t...</td>\n",
              "      <td>0.183333</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1695</th>\n",
              "      <td>1695</td>\n",
              "      <td>As you look at Wendy, you may see her hair bec...</td>\n",
              "      <td>0.097396</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1696</th>\n",
              "      <td>1696</td>\n",
              "      <td>THE END</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1697 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ... posNeg3\n",
              "0              0  ...     1.0\n",
              "1              1  ...     2.0\n",
              "2              2  ...     2.0\n",
              "3              3  ...     2.0\n",
              "4              4  ...     1.0\n",
              "...          ...  ...     ...\n",
              "1692        1692  ...     1.0\n",
              "1693        1693  ...     2.0\n",
              "1694        1694  ...     2.0\n",
              "1695        1695  ...     1.0\n",
              "1696        1696  ...     1.0\n",
              "\n",
              "[1697 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McBbf3p5Ny7k",
        "outputId": "db4b644a-d585-4912-a695-8768a961e863"
      },
      "source": [
        "sentences=data['sentence'].tolist()\n",
        "Y_data= data['posNeg3'].tolist()\n",
        "preprocess = hub.load(PREPROCESS_MODEL)\n",
        "bert = hub.load(BERT_MODEL)\n",
        "inputs = preprocess(sentences[:500])\n",
        "bert_results = bert(inputs)\n",
        "print(bert_results)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:10 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7fb6e99c4c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:10 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7fb6e99c4c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fb8ff9f24d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fb8ff9f24d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fb8f7a57ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fb8f7a57ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fb6e99c4f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fb6e99c4f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fb6e6d3a8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fb6e6d3a8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'encoder_outputs': [<tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 0.0011499 , -0.02532766,  0.0496476 , ...,  0.24924558,\n",
            "         -0.03188992,  0.00629036],\n",
            "        [ 0.5109046 , -0.61041427,  0.6048647 , ..., -0.20907308,\n",
            "         -0.40722883, -0.27833563],\n",
            "        [ 0.11850551, -0.34156585, -0.44050834, ..., -0.36718255,\n",
            "          0.03220936,  0.10791692],\n",
            "        ...,\n",
            "        [-0.17884171, -0.10139102,  0.364949  , ...,  0.34813005,\n",
            "         -0.18461484, -0.19746351],\n",
            "        [-0.09677637, -0.08950923,  0.47329453, ...,  0.4158615 ,\n",
            "         -0.21884018, -0.23421523],\n",
            "        [-0.10471042, -0.16743065,  0.4955452 , ...,  0.43011165,\n",
            "         -0.18079133, -0.2474733 ]],\n",
            "\n",
            "       [[ 0.02463844,  0.03560804,  0.04623216, ...,  0.2842862 ,\n",
            "         -0.00575601, -0.03268295],\n",
            "        [-0.12171297, -0.00797039, -0.35404497, ..., -0.62068224,\n",
            "         -0.12919202,  0.60665375],\n",
            "        [-0.9193618 , -0.15029505, -0.29354283, ..., -0.22051197,\n",
            "          0.7163553 ,  0.15699354],\n",
            "        ...,\n",
            "        [-0.7879036 ,  0.32684755,  0.42013225, ...,  0.49464706,\n",
            "          0.12442554,  0.15148266],\n",
            "        [-0.19095722,  0.20629764, -0.01200728, ...,  0.43248072,\n",
            "         -0.21268007, -0.15461595],\n",
            "        [-0.05351811,  0.20783919, -0.01300273, ...,  0.06382602,\n",
            "         -0.18032327, -0.0013136 ]],\n",
            "\n",
            "       [[ 0.01383607,  0.01121431,  0.03377088, ...,  0.26244426,\n",
            "         -0.02019709, -0.04831252],\n",
            "        [-0.05171994, -0.0644051 , -0.17015167, ..., -0.07799799,\n",
            "         -0.24715552, -0.30634058],\n",
            "        [ 0.5458118 , -0.18677774,  0.26605907, ...,  0.20900092,\n",
            "          0.45450225, -0.63687325],\n",
            "        ...,\n",
            "        [-0.18276402,  0.06781623,  0.42537862, ...,  0.27547178,\n",
            "         -0.18165934, -0.2008698 ],\n",
            "        [-0.11077208,  0.08787373,  0.5092583 , ...,  0.34917757,\n",
            "         -0.20449102, -0.22728589],\n",
            "        [-0.13103536,  0.02116314,  0.53417   , ...,  0.3740174 ,\n",
            "         -0.15939555, -0.2343395 ]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0.01707591,  0.04733104,  0.03764939, ...,  0.26367822,\n",
            "         -0.0129467 , -0.04558808],\n",
            "        [ 0.09004991, -0.396263  , -0.12870668, ...,  0.12851606,\n",
            "          0.71463174, -0.52109563],\n",
            "        [ 0.24707928, -0.36762396, -0.2979215 , ..., -0.26332688,\n",
            "          0.4599898 , -0.47260717],\n",
            "        ...,\n",
            "        [-0.18358873,  0.0251612 ,  0.43867806, ...,  0.2873499 ,\n",
            "         -0.2047421 , -0.20197177],\n",
            "        [-0.10220207,  0.03402307,  0.5433353 , ...,  0.3653211 ,\n",
            "         -0.2494972 , -0.23153438],\n",
            "        [-0.1151038 , -0.02726078,  0.5615765 , ...,  0.37633792,\n",
            "         -0.21565697, -0.24038152]],\n",
            "\n",
            "       [[ 0.02990765,  0.04159047,  0.04987365, ...,  0.20787492,\n",
            "         -0.00691459, -0.02414695],\n",
            "        [ 0.16626924, -0.5994643 , -0.32760605, ..., -0.6142419 ,\n",
            "         -0.5183346 , -0.31981796],\n",
            "        [ 0.4095742 , -0.31400415,  0.41406626, ..., -0.04199856,\n",
            "          0.21865141, -0.06567733],\n",
            "        ...,\n",
            "        [-0.17388031, -0.07212915,  0.38872263, ...,  0.3068604 ,\n",
            "         -0.11843517, -0.17314251],\n",
            "        [-0.10669402, -0.06105543,  0.48090145, ...,  0.36954746,\n",
            "         -0.15816736, -0.20489009],\n",
            "        [-0.10724378, -0.12974697,  0.5034414 , ...,  0.38092476,\n",
            "         -0.1214795 , -0.2203265 ]],\n",
            "\n",
            "       [[ 0.01792305,  0.05395286,  0.00793958, ...,  0.26993477,\n",
            "         -0.02259862, -0.04080463],\n",
            "        [ 0.30443856,  0.03935372,  0.07108971, ..., -0.4967541 ,\n",
            "         -0.3883691 ,  0.2826457 ],\n",
            "        [-0.02739063, -0.0102098 , -0.13412498, ..., -0.18876153,\n",
            "          0.1381558 , -0.59382695],\n",
            "        ...,\n",
            "        [-0.6232364 ,  0.16710097, -0.4678324 , ..., -0.01406692,\n",
            "         -0.23925108,  0.4615081 ],\n",
            "        [-0.09695435,  0.5375079 , -0.59874094, ..., -0.12968165,\n",
            "          0.7216414 , -0.37768227],\n",
            "        [-0.05246415,  0.21797678, -0.06023032, ...,  0.05074723,\n",
            "         -0.16467682, -0.02116589]]], dtype=float32)>, <tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 0.13755623,  0.04999614,  0.14151041, ...,  0.3020823 ,\n",
            "          0.05125778, -0.00147055],\n",
            "        [ 0.36940125, -0.01235455,  0.7652876 , ...,  0.13169318,\n",
            "         -0.29728898, -0.0665891 ],\n",
            "        [ 0.30131418, -0.20762423, -0.34555444, ...,  0.00398028,\n",
            "          0.65626806,  0.07323008],\n",
            "        ...,\n",
            "        [-0.09393989,  0.05794752,  0.17143458, ...,  0.20638117,\n",
            "         -0.0585161 , -0.20947836],\n",
            "        [ 0.01190124,  0.06633348,  0.29145023, ...,  0.2944863 ,\n",
            "         -0.10905182, -0.2890929 ],\n",
            "        [ 0.00798918,  0.0292313 ,  0.32328138, ...,  0.315002  ,\n",
            "         -0.10177927, -0.2798808 ]],\n",
            "\n",
            "       [[ 0.10270167,  0.030221  ,  0.16394699, ...,  0.4681244 ,\n",
            "          0.05676651, -0.02381156],\n",
            "        [-0.06332985,  0.14970383, -0.46591076, ..., -0.46014655,\n",
            "          0.01568752,  0.65398234],\n",
            "        [-0.5161638 , -0.03462715, -0.03671745, ...,  0.09401181,\n",
            "          0.46523815,  0.31832162],\n",
            "        ...,\n",
            "        [-0.6037621 ,  0.24030578,  0.1827827 , ...,  0.5310741 ,\n",
            "          0.17340973,  0.14911659],\n",
            "        [-0.1801773 ,  0.0974126 , -0.08835126, ...,  0.57820576,\n",
            "         -0.05125747, -0.21748649],\n",
            "        [-0.04133593,  0.10129077, -0.07734517, ...,  0.04311581,\n",
            "         -0.08283705, -0.02402673]],\n",
            "\n",
            "       [[ 0.07550517,  0.02567732,  0.12355582, ...,  0.4847438 ,\n",
            "          0.02709568, -0.03682359],\n",
            "        [ 0.32199818, -0.41954014, -0.4337554 , ..., -0.11650859,\n",
            "         -0.2482047 , -0.29320982],\n",
            "        [ 0.9946043 ,  0.63237596,  0.18016468, ...,  0.04180022,\n",
            "          0.4075488 , -0.89760864],\n",
            "        ...,\n",
            "        [-0.06236951,  0.282234  ,  0.09038899, ...,  0.14767717,\n",
            "         -0.09571195, -0.20746894],\n",
            "        [ 0.01832602,  0.31813282,  0.1758318 , ...,  0.22007112,\n",
            "         -0.10418664, -0.27455968],\n",
            "        [-0.05977672,  0.2689978 ,  0.20731893, ...,  0.23530954,\n",
            "         -0.06810981, -0.26991692]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0.14144279,  0.08000363,  0.0793866 , ...,  0.38797298,\n",
            "          0.04398093, -0.02422305],\n",
            "        [ 0.43910137, -0.38319528, -0.32627714, ...,  0.40056586,\n",
            "          0.6230822 , -0.77147466],\n",
            "        [ 0.3275342 , -0.3634233 , -0.38360375, ..., -0.0350235 ,\n",
            "          0.39593884, -0.66084725],\n",
            "        ...,\n",
            "        [-0.11445342,  0.23876086,  0.13191102, ...,  0.11540731,\n",
            "         -0.11322539, -0.17360696],\n",
            "        [ 0.01045697,  0.22874042,  0.26353142, ...,  0.22484577,\n",
            "         -0.12726736, -0.24787953],\n",
            "        [-0.00466173,  0.20792113,  0.31447867, ...,  0.24738106,\n",
            "         -0.11192232, -0.23570952]],\n",
            "\n",
            "       [[ 0.15709242,  0.12169099,  0.13739724, ...,  0.31761143,\n",
            "          0.01832094, -0.03544421],\n",
            "        [ 0.3151088 ,  0.03283451, -0.19030745, ..., -0.64367026,\n",
            "         -0.14093955, -0.38363492],\n",
            "        [ 0.7357253 ,  0.06848915,  0.28535742, ..., -0.0724209 ,\n",
            "          0.44431412, -0.04096338],\n",
            "        ...,\n",
            "        [-0.08703733,  0.19236094,  0.13819471, ...,  0.16186439,\n",
            "          0.00423985, -0.18674055],\n",
            "        [ 0.00813128,  0.19556256,  0.25784314, ...,  0.22683617,\n",
            "         -0.06792684, -0.2603178 ],\n",
            "        [-0.00940159,  0.17158794,  0.28672308, ...,  0.23349135,\n",
            "         -0.02835245, -0.25284073]],\n",
            "\n",
            "       [[ 0.09114294,  0.02392826,  0.07931036, ...,  0.41105258,\n",
            "         -0.0187272 , -0.04642392],\n",
            "        [ 0.5980227 , -0.09856983,  0.14344509, ..., -0.3428399 ,\n",
            "         -0.23348016,  0.21229632],\n",
            "        [ 0.13724029, -0.12562883, -0.19288014, ..., -0.01831838,\n",
            "          0.09056723, -0.65149087],\n",
            "        ...,\n",
            "        [-0.57914174, -0.01609123, -0.40564814, ...,  0.08388726,\n",
            "         -0.02466154,  0.4388424 ],\n",
            "        [-0.25116184,  0.447718  , -0.51314247, ...,  0.19223525,\n",
            "          0.6157476 , -0.38518342],\n",
            "        [-0.06631327,  0.08905817, -0.10708003, ...,  0.02676876,\n",
            "         -0.10794217, -0.08357175]]], dtype=float32)>, <tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 0.22401007, -0.02022554,  0.20085496, ...,  0.49260148,\n",
            "         -0.00306274,  0.00739972],\n",
            "        [ 0.14539026,  0.18761262,  0.20099184, ...,  0.2783887 ,\n",
            "         -0.28148332, -0.16491348],\n",
            "        [ 0.11824591, -0.09097344, -0.22362134, ...,  0.07363741,\n",
            "          0.48724028, -0.14831159],\n",
            "        ...,\n",
            "        [-0.00822864,  0.15161973,  0.02829594, ...,  0.15893698,\n",
            "         -0.07323717, -0.1244007 ],\n",
            "        [ 0.1456914 ,  0.18208966,  0.12371014, ...,  0.23692179,\n",
            "         -0.06960787, -0.17082632],\n",
            "        [ 0.10736349,  0.2215759 ,  0.12432335, ...,  0.2496072 ,\n",
            "         -0.05411308, -0.16431361]],\n",
            "\n",
            "       [[ 0.18072188, -0.01849476,  0.17967021, ...,  0.51505274,\n",
            "          0.07516553, -0.06694454],\n",
            "        [ 0.02314767,  0.31106398, -0.5273167 , ..., -0.33919182,\n",
            "          0.31046474,  0.5206077 ],\n",
            "        [-0.55966526, -0.10389619, -0.07887253, ...,  0.08135083,\n",
            "          0.13344923,  0.20811981],\n",
            "        ...,\n",
            "        [-0.4681989 ,  0.14494029,  0.37399518, ...,  0.27248505,\n",
            "          0.09206451, -0.08218123],\n",
            "        [-0.293597  ,  0.05711979, -0.12913387, ...,  0.4461047 ,\n",
            "         -0.14320469, -0.09442471],\n",
            "        [ 0.00534314,  0.01324348, -0.0896455 , ..., -0.03078264,\n",
            "         -0.03154305, -0.0073    ]],\n",
            "\n",
            "       [[ 0.1404249 , -0.01169293,  0.144765  , ...,  0.5899376 ,\n",
            "          0.07243856, -0.04081441],\n",
            "        [ 0.44429228, -0.11279882, -0.7013383 , ..., -0.42203546,\n",
            "         -0.08498015, -0.33147287],\n",
            "        [ 1.1361916 ,  0.7668325 ,  0.00805871, ..., -0.00923297,\n",
            "          0.5520712 , -0.643984  ],\n",
            "        ...,\n",
            "        [ 0.09305467,  0.12410843, -0.06156296, ...,  0.12174016,\n",
            "         -0.01888657, -0.15112433],\n",
            "        [ 0.2216388 ,  0.14893812,  0.02031119, ...,  0.20013165,\n",
            "         -0.02054779, -0.22683458],\n",
            "        [ 0.17431822,  0.13381183,  0.06907907, ...,  0.23384559,\n",
            "         -0.00130244, -0.22298747]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0.19821137, -0.01329264,  0.16769496, ...,  0.5423655 ,\n",
            "          0.03163652, -0.01040095],\n",
            "        [ 0.4053831 , -0.03003473, -0.21539399, ...,  0.09140379,\n",
            "          0.43984047, -0.9001113 ],\n",
            "        [ 0.10505567, -0.11001371, -0.23120166, ..., -0.17226225,\n",
            "          0.50409085, -0.7212488 ],\n",
            "        ...,\n",
            "        [ 0.02611033,  0.07917139, -0.01548734, ...,  0.12766747,\n",
            "         -0.07707872, -0.11555073],\n",
            "        [ 0.17069723,  0.07660924,  0.08207847, ...,  0.22029307,\n",
            "         -0.08028577, -0.17815563],\n",
            "        [ 0.17016354,  0.10185882,  0.13509493, ...,  0.2518154 ,\n",
            "         -0.0753745 , -0.15481457]],\n",
            "\n",
            "       [[ 0.17163894,  0.05928203,  0.1798704 , ...,  0.53182817,\n",
            "          0.03668704, -0.04901772],\n",
            "        [ 0.06870065,  0.10073046, -0.24281241, ..., -0.67941856,\n",
            "         -0.04540832, -0.44026345],\n",
            "        [ 0.66367203,  0.2274243 ,  0.18847363, ..., -0.21899204,\n",
            "          0.23088022, -0.26906472],\n",
            "        ...,\n",
            "        [-0.00888191,  0.20615913,  0.00464472, ...,  0.17502384,\n",
            "          0.00416926, -0.11501501],\n",
            "        [ 0.14950125,  0.2302044 ,  0.12136391, ...,  0.26078042,\n",
            "         -0.00117535, -0.17318124],\n",
            "        [ 0.09572111,  0.2760995 ,  0.12403077, ...,  0.26263043,\n",
            "          0.01335484, -0.16249049]],\n",
            "\n",
            "       [[ 0.12482505, -0.02279893,  0.16331796, ...,  0.6048493 ,\n",
            "          0.04011333, -0.01964387],\n",
            "        [ 0.46737412, -0.45295116,  0.02546882, ..., -0.3112683 ,\n",
            "         -0.04013204,  0.17994086],\n",
            "        [ 0.07787928, -0.23606807, -0.19582707, ...,  0.08172065,\n",
            "          0.19524145, -0.7804937 ],\n",
            "        ...,\n",
            "        [-0.46379963, -0.09862073, -0.39551628, ...,  0.22992367,\n",
            "         -0.03682868,  0.59241515],\n",
            "        [-0.19652851,  0.44127604, -0.38519922, ...,  0.13847369,\n",
            "          0.2807189 , -0.40572494],\n",
            "        [-0.04373598,  0.01231008, -0.08382262, ...,  0.0275015 ,\n",
            "         -0.01276486, -0.02613001]]], dtype=float32)>, <tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 1.15443565e-01, -1.15651980e-01,  1.11057535e-01, ...,\n",
            "          5.86227953e-01, -8.37686583e-02,  8.23970735e-02],\n",
            "        [ 1.62444070e-01,  1.36160739e-02,  5.71262300e-01, ...,\n",
            "          4.96150672e-01, -4.61001098e-01, -3.76636386e-01],\n",
            "        [-4.52615581e-02, -2.34125763e-01, -5.96877448e-02, ...,\n",
            "          2.46009439e-01, -5.51249757e-02, -2.00927317e-01],\n",
            "        ...,\n",
            "        [ 4.35544960e-02,  1.07544281e-01, -1.35279477e-01, ...,\n",
            "          1.86904073e-01,  5.07413596e-03, -7.94227421e-03],\n",
            "        [ 1.86677083e-01,  1.71944112e-01, -2.39739511e-02, ...,\n",
            "          2.65849054e-01,  2.59491540e-02, -8.65187049e-02],\n",
            "        [ 1.51620507e-01,  2.05627546e-01,  1.18956435e-02, ...,\n",
            "          2.78594315e-01,  3.65038589e-02, -8.59307200e-02]],\n",
            "\n",
            "       [[ 1.47279665e-01,  5.87047171e-03,  3.83372307e-01, ...,\n",
            "          5.98630369e-01,  2.39691697e-02, -6.10895902e-02],\n",
            "        [ 4.09978032e-01, -2.62805313e-01, -6.31234825e-01, ...,\n",
            "         -1.78268343e-01, -6.23801351e-03,  5.54260194e-01],\n",
            "        [-2.89580822e-01,  3.67363263e-03, -2.45814040e-01, ...,\n",
            "         -1.71062008e-01, -9.11892354e-02, -1.54286716e-02],\n",
            "        ...,\n",
            "        [-3.02786082e-01, -6.16108663e-02,  5.32146156e-01, ...,\n",
            "          5.76537073e-01,  3.20234209e-01, -6.06115460e-02],\n",
            "        [-3.34228814e-01,  2.84280270e-01, -6.62737191e-02, ...,\n",
            "          8.23800206e-01, -1.06329866e-01, -2.63251901e-01],\n",
            "        [-3.88433263e-02,  5.59447845e-03, -6.36439025e-03, ...,\n",
            "          3.34122777e-02,  4.21347097e-03, -4.39891592e-02]],\n",
            "\n",
            "       [[ 1.06988519e-01, -3.96056380e-03,  2.72711992e-01, ...,\n",
            "          6.46410823e-01,  4.32218164e-02, -6.68633282e-02],\n",
            "        [ 2.07923993e-01, -5.05269945e-01, -2.00018615e-01, ...,\n",
            "         -4.34676945e-01, -2.33821526e-01, -4.22673464e-01],\n",
            "        [ 7.34366894e-01, -8.11178908e-02, -2.73291826e-01, ...,\n",
            "          1.87768042e-01,  1.83562472e-01, -1.03638983e+00],\n",
            "        ...,\n",
            "        [ 1.02799281e-01,  1.85914755e-01, -1.22060306e-01, ...,\n",
            "          2.36038595e-01,  1.71834975e-03, -1.71257555e-01],\n",
            "        [ 1.66004777e-01,  1.66376814e-01, -4.60297838e-02, ...,\n",
            "          2.27487385e-01, -2.31433213e-02, -2.74164796e-01],\n",
            "        [ 1.09154552e-01,  1.81263849e-01,  1.12082034e-01, ...,\n",
            "          2.35176325e-01,  2.17639692e-02, -2.23347098e-01]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 2.23830640e-01, -2.42821053e-02,  2.85613298e-01, ...,\n",
            "          5.98632514e-01, -1.24887787e-02, -2.99010947e-02],\n",
            "        [ 5.66627443e-01, -3.18333477e-01, -1.76713079e-01, ...,\n",
            "          4.63131547e-01,  4.49589252e-01, -1.08290207e+00],\n",
            "        [ 2.17341632e-01,  1.33302972e-01, -3.86143595e-01, ...,\n",
            "         -2.98800856e-01,  4.38055336e-01, -9.51673985e-01],\n",
            "        ...,\n",
            "        [-1.17071770e-01, -5.07353693e-02,  7.76439905e-02, ...,\n",
            "          1.65966451e-01, -1.17755249e-01, -1.06770441e-01],\n",
            "        [ 1.23316988e-01, -4.29821946e-02,  8.74350220e-02, ...,\n",
            "          2.96955973e-01, -5.35717644e-02, -2.26847708e-01],\n",
            "        [ 2.17065126e-01,  5.96329793e-02,  1.18390009e-01, ...,\n",
            "          3.83754730e-01, -1.78375989e-02, -1.28823593e-01]],\n",
            "\n",
            "       [[ 1.21502727e-01,  8.06302056e-02,  2.74853379e-01, ...,\n",
            "          6.45515561e-01, -3.87140438e-02, -3.01180780e-02],\n",
            "        [ 4.28750217e-02, -3.19159120e-01, -1.28613845e-01, ...,\n",
            "         -3.99481535e-01, -2.75091290e-01, -2.16869175e-01],\n",
            "        [ 5.40341914e-01, -2.18028612e-02,  3.03522259e-01, ...,\n",
            "         -1.54284433e-01,  2.83454418e-01, -4.61205930e-01],\n",
            "        ...,\n",
            "        [ 9.53450650e-02,  1.29268959e-01, -1.08745702e-01, ...,\n",
            "          2.80079544e-01,  6.49474785e-02, -5.92729934e-02],\n",
            "        [ 2.69929975e-01,  1.70241624e-01,  2.98876967e-03, ...,\n",
            "          3.58680069e-01,  8.15237761e-02, -1.48819983e-01],\n",
            "        [ 2.07926348e-01,  1.91453412e-01,  3.46499905e-02, ...,\n",
            "          3.58872205e-01,  7.80861154e-02, -1.31820917e-01]],\n",
            "\n",
            "       [[ 1.48988590e-01,  3.17069236e-04,  3.27555507e-01, ...,\n",
            "          5.89994133e-01, -1.26474909e-02, -6.61972091e-02],\n",
            "        [ 5.77335119e-01, -2.48350471e-01,  3.02115411e-01, ...,\n",
            "         -1.30098119e-01, -4.24497098e-01,  3.02441381e-02],\n",
            "        [ 9.84587520e-02, -9.27526578e-02, -6.57863021e-02, ...,\n",
            "          1.40505075e-01,  1.39254741e-02, -7.54511654e-01],\n",
            "        ...,\n",
            "        [-5.05435169e-01, -1.22136980e-01, -3.81065756e-01, ...,\n",
            "          3.46582383e-01, -2.32482761e-01,  6.28038704e-01],\n",
            "        [-3.56012732e-01,  2.06442311e-01, -1.95815817e-01, ...,\n",
            "          2.85473526e-01, -1.54741734e-01, -5.25402963e-01],\n",
            "        [-5.40553778e-02,  1.80599000e-03, -9.03132651e-03, ...,\n",
            "          3.31985727e-02,  1.33071542e-02, -6.58444241e-02]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 0.17614524,  0.02254323,  0.19699323, ...,  0.7119303 ,\n",
            "         -0.06820749,  0.20129478],\n",
            "        [ 0.28498554, -0.11274597,  0.5796338 , ...,  0.5546914 ,\n",
            "         -0.38057616, -0.40638238],\n",
            "        [-0.07636564, -0.3978471 ,  0.08842532, ...,  0.38320205,\n",
            "         -0.07236084, -0.3014145 ],\n",
            "        ...,\n",
            "        [-0.14464107, -0.02723182, -0.05968384, ...,  0.0163432 ,\n",
            "          0.06523843, -0.01222189],\n",
            "        [ 0.07531993,  0.04395574, -0.01384105, ...,  0.18591136,\n",
            "          0.2253728 , -0.04038272],\n",
            "        [ 0.08668925,  0.22056048,  0.04240005, ...,  0.2708173 ,\n",
            "          0.22507277, -0.05882473]],\n",
            "\n",
            "       [[ 0.21752977,  0.18794341,  0.5172446 , ...,  0.75009423,\n",
            "          0.11859938, -0.01464023],\n",
            "        [ 0.33691478, -0.5401558 , -0.45860147, ..., -0.10890365,\n",
            "          0.05166946,  0.53762937],\n",
            "        [ 0.10006261, -0.07497945, -0.0941417 , ..., -0.26179948,\n",
            "          0.07991087,  0.01388398],\n",
            "        ...,\n",
            "        [-0.16837016, -0.0213859 ,  0.35738623, ...,  0.7046704 ,\n",
            "          0.09196325,  0.08479446],\n",
            "        [-0.41953415, -0.1749921 ,  0.22779381, ...,  0.4666347 ,\n",
            "         -0.05061664, -0.18549174],\n",
            "        [ 0.01517965,  0.0332547 , -0.05284267, ...,  0.01320758,\n",
            "          0.02007985, -0.01231338]],\n",
            "\n",
            "       [[ 0.21742445,  0.08539715,  0.5026567 , ...,  0.78713775,\n",
            "          0.09762426,  0.02875659],\n",
            "        [ 0.2880061 , -0.71849823,  0.2713266 , ..., -0.19817257,\n",
            "         -0.22556885, -0.54916435],\n",
            "        [ 0.43858415, -0.43814665, -0.47061187, ...,  0.12044144,\n",
            "          0.02737207, -1.1485497 ],\n",
            "        ...,\n",
            "        [ 0.09781401,  0.30521584, -0.2520632 , ...,  0.20880906,\n",
            "          0.06164399, -0.05576366],\n",
            "        [ 0.19745275,  0.16559277, -0.20426969, ...,  0.0314867 ,\n",
            "          0.05251828, -0.21816589],\n",
            "        [ 0.09870952,  0.10659023,  0.07189994, ...,  0.01870689,\n",
            "          0.06390714, -0.13637343]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0.2868932 ,  0.06756344,  0.4814527 , ...,  0.80326074,\n",
            "          0.02480284,  0.07013161],\n",
            "        [ 0.67091125, -0.20882905, -0.3271098 , ...,  0.4377141 ,\n",
            "          0.4905444 , -0.9361292 ],\n",
            "        [ 0.27806756, -0.0407285 , -0.34380352, ..., -0.5439251 ,\n",
            "          0.43468553, -1.1218562 ],\n",
            "        ...,\n",
            "        [-0.30699927,  0.07116245,  0.22548883, ...,  0.18370973,\n",
            "         -0.0437866 , -0.07649232],\n",
            "        [ 0.06321205,  0.06332589,  0.15771338, ...,  0.34457356,\n",
            "         -0.00629888, -0.14821608],\n",
            "        [ 0.24966416,  0.01446344,  0.09145963, ...,  0.5417807 ,\n",
            "         -0.07593701, -0.06087441]],\n",
            "\n",
            "       [[ 0.16576488,  0.19595158,  0.44164717, ...,  0.81921756,\n",
            "          0.04851547,  0.04625718],\n",
            "        [-0.23962419, -0.54975283, -0.1948559 , ...,  0.13809614,\n",
            "         -0.02472468, -0.14833075],\n",
            "        [ 0.56125766, -0.29192492,  0.6134817 , ..., -0.11042908,\n",
            "          0.14869314, -0.4221393 ],\n",
            "        ...,\n",
            "        [-0.04596388,  0.06945066, -0.00251594, ...,  0.17841105,\n",
            "          0.2610935 , -0.0752669 ],\n",
            "        [ 0.22648656,  0.23274049,  0.02541821, ...,  0.33113465,\n",
            "          0.3128759 , -0.13368034],\n",
            "        [ 0.1863376 ,  0.20063004,  0.11843085, ...,  0.3425859 ,\n",
            "          0.3130837 , -0.10660088]],\n",
            "\n",
            "       [[ 0.2263158 ,  0.11513972,  0.4908641 , ...,  0.762494  ,\n",
            "          0.04593549,  0.03176759],\n",
            "        [ 0.65482473, -0.19761673,  0.34208402, ..., -0.01601085,\n",
            "         -0.05283111,  0.05693815],\n",
            "        [ 0.35271484, -0.317401  ,  0.01644623, ...,  0.15205607,\n",
            "         -0.15321898, -0.6308986 ],\n",
            "        ...,\n",
            "        [-0.576595  , -0.13722734, -0.4143964 , ...,  0.44350028,\n",
            "          0.11449505,  0.55935454],\n",
            "        [-0.21928772,  0.02326679, -0.12335838, ..., -0.06408677,\n",
            "         -0.38159177, -0.8058071 ],\n",
            "        [ 0.00843062,  0.03510629, -0.06888075, ...,  0.02119911,\n",
            "          0.02997676, -0.03778406]]], dtype=float32)>, <tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 0.18560573, -0.01770124,  0.20174494, ...,  0.59443927,\n",
            "          0.03739442,  0.10648069],\n",
            "        [ 0.13685353,  0.26894477,  0.19674277, ...,  0.74924266,\n",
            "         -0.38556865, -0.28875512],\n",
            "        [-0.07102242, -0.26390803, -0.06538888, ...,  0.30245078,\n",
            "         -0.06846469, -0.12026751],\n",
            "        ...,\n",
            "        [-0.20067585,  0.14359182, -0.15292877, ..., -0.02987547,\n",
            "          0.3450033 ,  0.09532657],\n",
            "        [ 0.01616647,  0.18805434, -0.09463795, ...,  0.13543622,\n",
            "          0.409861  ,  0.06676082],\n",
            "        [ 0.02372274,  0.36276045,  0.0299792 , ...,  0.24019636,\n",
            "          0.3975013 ,  0.00160981]],\n",
            "\n",
            "       [[ 0.10115428,  0.25460643,  0.44487086, ...,  0.70412475,\n",
            "          0.11582901, -0.09963863],\n",
            "        [ 0.14053881, -0.3261439 , -0.15267946, ..., -0.04502388,\n",
            "         -0.32182497,  0.47204965],\n",
            "        [-0.03938651,  0.04662132, -0.15407047, ..., -0.4009802 ,\n",
            "         -0.25199884,  0.04189797],\n",
            "        ...,\n",
            "        [-0.12087847, -0.08261036,  0.55528617, ...,  0.64654726,\n",
            "          0.16000225, -0.05575337],\n",
            "        [-0.56231624, -0.1299443 ,  0.49902192, ...,  0.18825123,\n",
            "          0.2774604 , -0.1965612 ],\n",
            "        [ 0.00142008,  0.01773761, -0.03045304, ..., -0.03377455,\n",
            "          0.04691987, -0.06505266]],\n",
            "\n",
            "       [[ 0.10376349,  0.21373995,  0.41228902, ...,  0.7089005 ,\n",
            "          0.02126594, -0.03950179],\n",
            "        [ 0.2259218 , -0.51535803,  0.2315076 , ..., -0.17240082,\n",
            "          0.12268918, -0.67174447],\n",
            "        [ 0.4454022 ,  0.08202313, -0.495367  , ..., -0.16786996,\n",
            "         -0.5952045 , -1.027598  ],\n",
            "        ...,\n",
            "        [ 0.00725475,  0.41866815, -0.22316644, ...,  0.15582259,\n",
            "          0.17049365, -0.06351189],\n",
            "        [ 0.119666  ,  0.28976625, -0.1678385 , ..., -0.08534035,\n",
            "          0.18406633, -0.21191733],\n",
            "        [-0.06982689,  0.32363725,  0.07087857, ..., -0.15883884,\n",
            "          0.15037227, -0.10694932]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0.21172735,  0.16206568,  0.36799908, ...,  0.7770427 ,\n",
            "         -0.03486625, -0.01224225],\n",
            "        [ 0.6348474 , -0.22092867, -0.21753676, ...,  0.18815285,\n",
            "          0.09860887, -0.8455419 ],\n",
            "        [ 0.2944496 , -0.21855631, -0.3192765 , ..., -0.684133  ,\n",
            "          0.39715216, -1.300618  ],\n",
            "        ...,\n",
            "        [-0.53572655,  0.25431633,  0.22429235, ...,  0.02948315,\n",
            "         -0.0448954 , -0.03003364],\n",
            "        [-0.16158012,  0.25396076,  0.18506272, ...,  0.3034781 ,\n",
            "         -0.02772129, -0.09437708],\n",
            "        [ 0.21370246,  0.12351105,  0.16091804, ...,  0.5893501 ,\n",
            "         -0.11193392, -0.07160632]],\n",
            "\n",
            "       [[ 0.05291861,  0.15822826,  0.28279144, ...,  0.72642684,\n",
            "          0.03810013, -0.00143453],\n",
            "        [-0.29752696, -0.18930751,  0.36463255, ...,  0.3907488 ,\n",
            "          0.26871222, -0.05057787],\n",
            "        [ 0.5576568 , -0.13043934,  0.36542317, ..., -0.19249961,\n",
            "          0.15000792, -0.53999454],\n",
            "        ...,\n",
            "        [-0.1483182 , -0.00935427, -0.08513975, ...,  0.05024156,\n",
            "          0.3886991 , -0.03644247],\n",
            "        [ 0.18052697,  0.1558674 , -0.02552396, ...,  0.20250857,\n",
            "          0.36628607, -0.11929588],\n",
            "        [ 0.12034364,  0.14503744,  0.0621484 , ...,  0.22673701,\n",
            "          0.3939663 , -0.11331081]],\n",
            "\n",
            "       [[ 0.05590048,  0.17871447,  0.4192604 , ...,  0.7166774 ,\n",
            "          0.00795772, -0.0224367 ],\n",
            "        [ 0.28701276, -0.49742368,  0.21849564, ...,  0.01623067,\n",
            "         -0.06609766,  0.05421323],\n",
            "        [ 0.20222342, -0.46326506, -0.04591414, ...,  0.18015559,\n",
            "         -0.087968  , -0.52303874],\n",
            "        ...,\n",
            "        [-0.91390896, -0.08804604, -0.14233218, ...,  0.60863626,\n",
            "          0.01859427,  0.2708463 ],\n",
            "        [-0.48085245,  0.13560504, -0.2579947 , ...,  0.01388306,\n",
            "         -0.10508363, -0.7401776 ],\n",
            "        [-0.02300043,  0.00174793, -0.06221395, ..., -0.03283633,\n",
            "          0.054216  , -0.07203202]]], dtype=float32)>, <tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 0.06924381,  0.10026927,  0.09297797, ...,  0.5207268 ,\n",
            "          0.03030371,  0.14278069],\n",
            "        [ 0.15295924,  0.12194433,  0.19275837, ...,  0.70428896,\n",
            "          0.07978101, -0.14189377],\n",
            "        [-0.17447373, -0.08619591, -0.19868144, ...,  0.31239802,\n",
            "         -0.13788387, -0.11858162],\n",
            "        ...,\n",
            "        [-0.23568651,  0.08959176, -0.25378832, ..., -0.12555012,\n",
            "          0.33114702,  0.13969871],\n",
            "        [-0.08970629,  0.04180375, -0.19054164, ...,  0.02501561,\n",
            "          0.44543317,  0.06962848],\n",
            "        [ 0.00475806,  0.14646198, -0.18409564, ...,  0.260664  ,\n",
            "          0.4179853 ,  0.02182797]],\n",
            "\n",
            "       [[ 0.00903963,  0.18845035,  0.1382775 , ...,  0.48056155,\n",
            "          0.37243438,  0.06429553],\n",
            "        [ 0.36374614, -0.14378738, -0.06938498, ..., -0.02781211,\n",
            "         -0.17797264,  0.51819396],\n",
            "        [-0.12229049, -0.09249842, -0.34087077, ..., -0.46844625,\n",
            "         -0.03203055,  0.1030334 ],\n",
            "        ...,\n",
            "        [ 0.422366  ,  0.24688402,  0.46735936, ...,  0.36073786,\n",
            "          0.22869791, -0.0128718 ],\n",
            "        [-0.3809174 , -0.02793807,  0.37201533, ..., -0.0510524 ,\n",
            "          0.61719006, -0.0933872 ],\n",
            "        [ 0.01404753,  0.02172138, -0.02877661, ..., -0.03584076,\n",
            "          0.04602814, -0.11688685]],\n",
            "\n",
            "       [[ 0.06345869,  0.17750117,  0.13397814, ...,  0.4878111 ,\n",
            "          0.32666758,  0.11551093],\n",
            "        [ 0.29861006, -0.65557647,  0.16587599, ...,  0.02163444,\n",
            "         -0.3002255 , -0.6699182 ],\n",
            "        [ 0.46708745, -0.10799581, -0.40523815, ..., -0.21110168,\n",
            "         -0.6495345 , -1.1912214 ],\n",
            "        ...,\n",
            "        [ 0.10206239,  0.15987611, -0.22632378, ...,  0.14569384,\n",
            "          0.09863392, -0.05179159],\n",
            "        [ 0.11969736,  0.10358766, -0.18547267, ..., -0.13838898,\n",
            "          0.12776315, -0.19876695],\n",
            "        [-0.17441766,  0.0813213 , -0.06707008, ..., -0.21981403,\n",
            "          0.11018909, -0.10472049]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0.16309956,  0.13888392,  0.11906044, ...,  0.5861616 ,\n",
            "          0.16127822,  0.11953554],\n",
            "        [ 0.81110185, -0.28696913, -0.49271348, ...,  0.29685086,\n",
            "          0.06310233, -0.7507065 ],\n",
            "        [ 0.143047  , -0.09128366, -0.3511878 , ..., -0.62252903,\n",
            "          0.13879398, -1.2481179 ],\n",
            "        ...,\n",
            "        [-0.7027961 , -0.03392168,  0.21079898, ..., -0.06010159,\n",
            "         -0.0173576 ,  0.01375736],\n",
            "        [-0.40069693,  0.00233543,  0.06697333, ...,  0.15798375,\n",
            "         -0.05455437, -0.08946489],\n",
            "        [ 0.04317759, -0.03212142,  0.03394859, ...,  0.5101782 ,\n",
            "         -0.20601724, -0.11476339]],\n",
            "\n",
            "       [[ 0.01440525,  0.08555788,  0.08389254, ...,  0.6002105 ,\n",
            "          0.18230693,  0.11194339],\n",
            "        [-0.01565094, -0.34315333,  0.546212  , ...,  0.3554591 ,\n",
            "          0.25691536, -0.053597  ],\n",
            "        [ 0.52639663, -0.47564632,  0.78964126, ..., -0.17297989,\n",
            "          0.33765215, -0.5029962 ],\n",
            "        ...,\n",
            "        [-0.11589757,  0.05167653, -0.20534989, ..., -0.0498773 ,\n",
            "          0.47784454, -0.07716068],\n",
            "        [ 0.15260553,  0.15373838, -0.2112888 , ...,  0.11284418,\n",
            "          0.40414128, -0.19196656],\n",
            "        [ 0.09183617,  0.15111667, -0.1741842 , ...,  0.11621443,\n",
            "          0.40382308, -0.17543975]],\n",
            "\n",
            "       [[ 0.02147297,  0.15332486,  0.1575549 , ...,  0.47155538,\n",
            "          0.29741395,  0.15955833],\n",
            "        [ 0.3451759 , -0.10233651,  0.27439603, ...,  0.1892544 ,\n",
            "         -0.03747751,  0.04591584],\n",
            "        [ 0.18051612, -0.14652403,  0.09757443, ...,  0.22141452,\n",
            "         -0.16193737, -0.59726423],\n",
            "        ...,\n",
            "        [-0.7326383 ,  0.07472599,  0.01207322, ...,  0.41209754,\n",
            "          0.31530792,  0.10811187],\n",
            "        [-0.4303401 ,  0.17510393, -0.10097834, ..., -0.04369248,\n",
            "          0.37971863, -0.71454245],\n",
            "        [ 0.00942976,  0.03598994, -0.0434396 , ..., -0.03049269,\n",
            "          0.04486639, -0.10597702]]], dtype=float32)>, <tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 1.37300372e-01,  1.54877961e-01,  1.54182374e-01, ...,\n",
            "          4.02895868e-01,  1.44454837e-03,  1.15405701e-01],\n",
            "        [-6.07244037e-02,  2.09163859e-01,  5.30253313e-02, ...,\n",
            "          5.99424303e-01, -7.47921914e-02,  4.46769148e-02],\n",
            "        [-3.24006200e-01, -1.20500505e-01, -2.56614424e-02, ...,\n",
            "          1.89905852e-01, -3.90322447e-01,  1.38184115e-01],\n",
            "        ...,\n",
            "        [-1.36121720e-01, -2.35192940e-01, -1.58982754e-01, ...,\n",
            "         -2.96340466e-01,  2.43397236e-01,  3.18961084e-01],\n",
            "        [ 2.04906724e-02, -2.47965038e-01, -1.44569650e-01, ...,\n",
            "         -2.45944917e-01,  3.16064328e-01,  2.50761926e-01],\n",
            "        [ 1.06514946e-01, -6.62751198e-02, -2.05866605e-01, ...,\n",
            "          1.31312758e-03,  4.05947864e-01,  1.50454685e-01]],\n",
            "\n",
            "       [[ 5.03703579e-02, -2.55644560e-01,  1.99364439e-01, ...,\n",
            "          4.62781578e-01,  3.14371824e-01,  1.96980909e-02],\n",
            "        [ 1.39186606e-01, -1.71238512e-01, -5.34868985e-02, ...,\n",
            "         -2.05388665e-03, -4.60155576e-01,  4.35124934e-01],\n",
            "        [-7.40783662e-03, -2.04968050e-01, -3.94161105e-01, ...,\n",
            "         -4.16815966e-01, -2.11210012e-01,  1.86981916e-01],\n",
            "        ...,\n",
            "        [ 3.05667281e-01, -2.81033516e-01,  1.61350995e-01, ...,\n",
            "          1.31866485e-01,  7.42907897e-02,  9.39593762e-02],\n",
            "        [-3.53899151e-01, -5.67189097e-01,  3.54096353e-01, ...,\n",
            "         -2.13942885e-01, -1.25990845e-02,  6.26979098e-02],\n",
            "        [ 3.25690508e-02, -1.24576967e-03, -1.80509500e-03, ...,\n",
            "         -3.49178426e-02,  2.54023522e-02, -3.41938809e-02]],\n",
            "\n",
            "       [[ 1.03315651e-01, -2.00463861e-01,  1.87689275e-01, ...,\n",
            "          4.45110053e-01,  3.05138052e-01,  5.61204180e-02],\n",
            "        [ 3.27073932e-01, -4.62405384e-01, -2.99474508e-01, ...,\n",
            "         -7.78370649e-02, -1.10748008e-01, -6.59632742e-01],\n",
            "        [ 5.85934937e-01, -7.72213042e-02, -3.40151221e-01, ...,\n",
            "         -4.53628838e-01, -4.54916775e-01, -1.04134381e+00],\n",
            "        ...,\n",
            "        [-1.82603039e-02,  1.02892548e-01, -4.17608887e-01, ...,\n",
            "          1.56837136e-01,  1.50088608e-01,  7.56257847e-02],\n",
            "        [-6.58837706e-03,  1.16357982e-01, -3.51944923e-01, ...,\n",
            "         -1.81765780e-01,  1.27639055e-01, -5.29794693e-02],\n",
            "        [-2.76576877e-01,  1.39881954e-01, -1.37165397e-01, ...,\n",
            "         -3.29062998e-01,  1.04342058e-01,  2.29862779e-02]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 2.00981379e-01, -1.85077667e-01,  6.54796809e-02, ...,\n",
            "          5.58333874e-01,  2.20664129e-01,  1.11236088e-01],\n",
            "        [ 9.83538151e-01, -4.97181684e-01, -1.93268210e-01, ...,\n",
            "          1.01622641e-01, -8.63804519e-02, -9.14108276e-01],\n",
            "        [ 3.19053531e-01, -1.98386490e-01, -1.58682764e-01, ...,\n",
            "         -7.21908391e-01,  2.26611998e-02, -1.05507994e+00],\n",
            "        ...,\n",
            "        [-6.42165780e-01, -3.13340016e-02,  3.26215662e-03, ...,\n",
            "         -3.48492056e-01, -5.57301193e-02,  6.66167140e-02],\n",
            "        [-5.29471636e-01,  3.88936959e-02, -6.56870753e-02, ...,\n",
            "         -8.83426890e-02, -7.28040487e-02, -4.45824936e-02],\n",
            "        [-9.77320150e-02,  4.69264574e-02, -3.00537013e-02, ...,\n",
            "          2.27909118e-01, -2.18404979e-01, -1.95825920e-02]],\n",
            "\n",
            "       [[ 3.02813184e-02, -2.57224232e-01,  7.45682232e-03, ...,\n",
            "          6.48037970e-01,  1.27086818e-01,  7.29245916e-02],\n",
            "        [-3.74331564e-01, -4.09955293e-01,  4.19860125e-01, ...,\n",
            "          3.80823135e-01,  3.11288774e-01, -8.46013427e-03],\n",
            "        [ 4.94794875e-01, -6.82532310e-01,  9.42698240e-01, ...,\n",
            "          1.07984267e-01,  4.89923298e-01, -4.01607871e-01],\n",
            "        ...,\n",
            "        [ 9.87977982e-02, -1.60089999e-01, -1.44457549e-01, ...,\n",
            "         -1.60484761e-01,  2.79734313e-01,  1.64867029e-01],\n",
            "        [ 3.17611307e-01,  7.85613507e-02, -2.29933411e-01, ...,\n",
            "         -2.08175331e-02,  2.57596642e-01,  2.11355984e-02],\n",
            "        [ 2.45936632e-01,  3.67003307e-02, -2.37939253e-01, ...,\n",
            "         -3.03350519e-02,  2.48309523e-01,  1.43627822e-02]],\n",
            "\n",
            "       [[ 1.47230670e-01, -3.17249209e-01,  1.71638608e-01, ...,\n",
            "          5.25525212e-01,  1.95773810e-01,  4.12154421e-02],\n",
            "        [ 5.50534010e-01, -4.44680035e-01,  4.13308084e-01, ...,\n",
            "          3.38613242e-01,  3.14179629e-01,  8.46363604e-02],\n",
            "        [ 4.90043223e-01, -5.78197181e-01,  1.84892848e-01, ...,\n",
            "          4.78779018e-01,  3.43637705e-01, -4.38140929e-01],\n",
            "        ...,\n",
            "        [-4.09486920e-01,  1.45733833e-01, -1.95653915e-01, ...,\n",
            "          1.22546420e-01,  3.14928889e-01,  1.75655425e-01],\n",
            "        [-4.37086791e-01,  7.87430704e-02,  5.15969694e-02, ...,\n",
            "         -7.81111717e-02,  5.75018704e-01, -5.57912767e-01],\n",
            "        [ 2.67777182e-02,  3.41868959e-04, -4.37874440e-03, ...,\n",
            "         -3.06171495e-02,  1.55075388e-02, -3.37453894e-02]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 9.73244607e-02,  2.75994122e-01,  1.39736399e-01, ...,\n",
            "          1.56458214e-01, -5.43057084e-01,  8.59230161e-02],\n",
            "        [ 1.38700321e-01, -1.13412738e-01,  2.04333320e-01, ...,\n",
            "          4.77531970e-01, -1.54064402e-01,  1.25317514e-01],\n",
            "        [-4.26406235e-01, -1.55751646e-01,  1.38797015e-01, ...,\n",
            "          1.31800681e-01, -5.29976428e-01,  1.58690870e-01],\n",
            "        ...,\n",
            "        [-1.66436672e-01, -6.24032378e-01, -2.19961643e-01, ...,\n",
            "         -3.62767637e-01,  3.23526144e-01,  2.95746088e-01],\n",
            "        [-5.76486066e-02, -5.77509344e-01, -2.90687859e-01, ...,\n",
            "         -3.04513842e-01,  3.14907849e-01,  2.39629388e-01],\n",
            "        [ 7.95356035e-02, -5.78470051e-01, -1.63855150e-01, ...,\n",
            "         -1.07262962e-01,  2.39245400e-01,  1.14324316e-01]],\n",
            "\n",
            "       [[ 9.67237279e-02, -5.44439256e-01,  2.51998782e-01, ...,\n",
            "          1.49092302e-01,  8.84757657e-03,  4.12592851e-02],\n",
            "        [ 3.02057505e-01, -1.76910847e-01,  3.49465668e-01, ...,\n",
            "         -1.63978338e-01, -6.61135912e-01,  3.77812535e-01],\n",
            "        [-3.63896508e-03, -1.64262116e-01, -3.37897874e-02, ...,\n",
            "         -4.87668812e-01, -3.42756718e-01,  2.48365521e-01],\n",
            "        ...,\n",
            "        [ 3.17257673e-01,  2.54423991e-02,  5.34408331e-01, ...,\n",
            "          3.55720580e-01, -1.01656124e-01,  1.88276201e-01],\n",
            "        [-7.06492141e-02, -3.24027926e-01,  3.72772306e-01, ...,\n",
            "         -4.17922586e-02, -2.60366887e-01, -6.20435402e-02],\n",
            "        [ 3.72448340e-02,  1.66630819e-02, -1.85936783e-02, ...,\n",
            "         -3.52719687e-02, -3.75555176e-03, -2.85378620e-02]],\n",
            "\n",
            "       [[ 1.13945857e-01, -5.32671750e-01,  3.30488741e-01, ...,\n",
            "          1.75006777e-01,  1.39670372e-01,  5.06276712e-02],\n",
            "        [ 4.72441584e-01, -9.46766436e-02,  2.84643769e-01, ...,\n",
            "          1.54268160e-01, -4.05015081e-01, -5.43406487e-01],\n",
            "        [ 7.02762306e-01, -1.65646940e-01, -1.12881854e-01, ...,\n",
            "         -4.36581641e-01, -6.58408642e-01, -9.35267508e-01],\n",
            "        ...,\n",
            "        [ 1.24432057e-01,  2.29442164e-01, -1.39477596e-01, ...,\n",
            "          3.06195468e-01, -9.91978049e-02,  2.47337446e-01],\n",
            "        [ 1.22830220e-01, -1.91451050e-04, -7.20480904e-02, ...,\n",
            "         -1.87779099e-01, -3.50598060e-02,  5.77924028e-03],\n",
            "        [-1.75030112e-01, -1.36248797e-01, -1.27863139e-04, ...,\n",
            "         -4.56567943e-01,  6.51626438e-02,  7.81588778e-02]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 2.04417616e-01, -3.65564555e-01,  4.69682068e-02, ...,\n",
            "          3.45979214e-01,  2.65592895e-02,  5.59506826e-02],\n",
            "        [ 6.34592295e-01, -4.54126477e-01, -1.18153632e-01, ...,\n",
            "          8.26529339e-02, -9.70878601e-02, -8.94721031e-01],\n",
            "        [ 4.51484434e-02, -7.88022205e-03,  2.31392160e-01, ...,\n",
            "         -5.44842660e-01, -1.14293396e-01, -6.55942082e-01],\n",
            "        ...,\n",
            "        [-6.49873197e-01,  3.42824422e-02,  1.69059366e-01, ...,\n",
            "         -3.39906812e-01, -6.45529181e-02, -1.78553946e-02],\n",
            "        [-6.14876151e-01,  1.02032334e-01, -2.30249092e-02, ...,\n",
            "         -1.93690076e-01,  1.87474452e-02, -3.52327041e-02],\n",
            "        [-2.81314939e-01,  9.91897434e-02, -6.10964820e-02, ...,\n",
            "          1.73750043e-01, -7.71735385e-02,  2.59674564e-02]],\n",
            "\n",
            "       [[ 2.11211927e-02, -4.43716466e-01,  2.70271778e-01, ...,\n",
            "          2.80941337e-01,  2.46106740e-03,  2.19197050e-02],\n",
            "        [ 4.34706882e-02, -1.64924473e-01,  3.03504258e-01, ...,\n",
            "          3.01306337e-01,  5.00297308e-01,  1.07533760e-01],\n",
            "        [ 4.76344049e-01, -4.63006765e-01,  6.67777061e-01, ...,\n",
            "          6.40688688e-02,  8.45019639e-01, -4.57667470e-01],\n",
            "        ...,\n",
            "        [-1.87600642e-01, -5.79422891e-01, -1.88315094e-01, ...,\n",
            "         -2.80544162e-01,  1.46503732e-01,  7.25549310e-02],\n",
            "        [ 6.62749708e-02, -3.55879694e-01, -1.62748799e-01, ...,\n",
            "         -1.54194385e-01,  8.53642598e-02, -1.37799546e-01],\n",
            "        [ 1.65686943e-02, -3.71447980e-01, -1.52936131e-01, ...,\n",
            "         -1.68051779e-01,  7.05054924e-02, -1.21719413e-01]],\n",
            "\n",
            "       [[ 1.24541603e-01, -6.09778166e-01,  2.93476433e-01, ...,\n",
            "          3.64543408e-01,  9.15760547e-02,  2.95805186e-02],\n",
            "        [ 5.32558680e-01, -5.00631869e-01,  3.88818443e-01, ...,\n",
            "          5.64063787e-01, -2.29108315e-02,  1.59004197e-01],\n",
            "        [ 3.36905807e-01, -2.94863641e-01,  2.29414850e-01, ...,\n",
            "          7.08602071e-01, -7.04216771e-03, -3.66062641e-01],\n",
            "        ...,\n",
            "        [-3.83648634e-01, -2.96351343e-01, -3.09047580e-01, ...,\n",
            "          1.55641049e-01, -2.94505805e-01,  1.36797115e-01],\n",
            "        [-3.22548360e-01,  5.66409864e-02, -3.77951294e-01, ...,\n",
            "         -1.96727276e-01,  8.92215669e-02, -5.75881243e-01],\n",
            "        [ 3.11116520e-02,  5.87950507e-03, -1.42252967e-02, ...,\n",
            "         -2.71693971e-02, -6.80486951e-03, -3.17948349e-02]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 8.32613230e-01, -8.63052085e-02,  8.27189744e-01, ...,\n",
            "          5.52346170e-01, -4.18427289e-01,  1.89254194e-01],\n",
            "        [ 3.50949168e-01, -1.50424689e-01,  2.86265194e-01, ...,\n",
            "          7.29438484e-01, -3.45892996e-01,  8.19831342e-02],\n",
            "        [-2.69984961e-01, -2.57056683e-01,  3.46518427e-01, ...,\n",
            "          3.18776071e-01, -4.13728893e-01,  1.54570997e-01],\n",
            "        ...,\n",
            "        [ 1.95403546e-01, -4.74938899e-02,  9.62014496e-02, ...,\n",
            "         -2.35677004e-01, -1.32759273e-01,  2.72013307e-01],\n",
            "        [ 1.59964010e-01, -5.42218685e-02,  4.27854620e-02, ...,\n",
            "         -9.82351899e-02, -1.71648651e-01,  2.57401586e-01],\n",
            "        [ 3.55122775e-01, -6.06363267e-02,  6.03990592e-02, ...,\n",
            "          1.34562820e-01, -1.73894674e-01,  1.91870525e-01]],\n",
            "\n",
            "       [[ 7.64819384e-01, -4.71328944e-02,  5.34686387e-01, ...,\n",
            "         -2.02591389e-01, -2.94829961e-02, -2.26056427e-01],\n",
            "        [ 2.27511436e-01, -3.91487539e-01,  2.47036487e-01, ...,\n",
            "          6.87136948e-02, -1.10872841e+00,  1.02174774e-01],\n",
            "        [-4.59242277e-02, -2.43574321e-01,  2.98958495e-02, ...,\n",
            "         -2.58545876e-01, -7.23097801e-01, -5.20614013e-02],\n",
            "        ...,\n",
            "        [ 3.38053554e-01,  1.74909279e-01,  6.89642191e-01, ...,\n",
            "          3.33527207e-01, -2.31726468e-01,  1.61062494e-01],\n",
            "        [ 4.03530747e-01,  7.00014383e-02,  6.72534466e-01, ...,\n",
            "          3.58138204e-01, -1.49446666e-01,  2.63107985e-01],\n",
            "        [ 1.03243617e-02,  1.27038201e-02, -2.67935824e-02, ...,\n",
            "         -2.57413872e-02, -1.13121327e-03,  6.32529147e-04]],\n",
            "\n",
            "       [[ 7.54433095e-01, -1.65134504e-01,  6.54092550e-01, ...,\n",
            "         -1.47491738e-01, -1.44800231e-01, -2.32127249e-01],\n",
            "        [ 8.77526104e-01, -1.11699268e-01,  2.21894562e-01, ...,\n",
            "          4.29044187e-01, -1.13603279e-01, -5.59518397e-01],\n",
            "        [ 6.07299805e-01, -3.41808230e-01,  1.62557989e-01, ...,\n",
            "         -3.18347454e-01, -3.86760443e-01, -1.01438427e+00],\n",
            "        ...,\n",
            "        [ 4.43746686e-01,  3.95691544e-01,  1.61679834e-01, ...,\n",
            "          9.36907902e-02, -1.66037276e-01,  2.60096431e-01],\n",
            "        [ 4.36985463e-01,  2.19504341e-01,  3.33724737e-01, ...,\n",
            "         -1.03247225e-01, -7.92581737e-02, -1.41453911e-02],\n",
            "        [ 1.62305102e-01,  9.10272375e-02,  4.21592087e-01, ...,\n",
            "         -3.97065848e-01,  6.85170963e-02,  1.14134084e-02]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 5.81926048e-01, -7.53171667e-02,  2.06562489e-01, ...,\n",
            "          4.82145101e-02, -2.35209823e-01,  5.15914224e-02],\n",
            "        [ 6.04294181e-01, -1.68176338e-01,  2.13207193e-02, ...,\n",
            "          1.95505843e-01, -4.41331267e-01, -8.68593276e-01],\n",
            "        [ 3.76460999e-02,  1.47762984e-01,  1.56079561e-01, ...,\n",
            "         -4.62131590e-01, -1.11116678e-01, -4.85009581e-01],\n",
            "        ...,\n",
            "        [-4.45346236e-01,  8.56704339e-02,  5.57308555e-01, ...,\n",
            "         -5.55110097e-01,  6.72495663e-02, -2.33820423e-01],\n",
            "        [-5.58595240e-01,  1.98276997e-01,  2.75529385e-01, ...,\n",
            "         -4.92450684e-01,  1.02689028e-01, -1.82070494e-01],\n",
            "        [-4.05306935e-01,  1.32003307e-01,  1.53805226e-01, ...,\n",
            "          5.46903424e-02,  6.35650903e-02, -1.64405629e-03]],\n",
            "\n",
            "       [[ 8.52170527e-01, -1.51121721e-01,  3.28320980e-01, ...,\n",
            "          1.43114299e-01, -3.89906615e-01,  1.34728566e-01],\n",
            "        [ 3.93891901e-01, -3.96864176e-01,  3.42276752e-01, ...,\n",
            "         -8.78163800e-03,  6.36106580e-02, -8.43236446e-02],\n",
            "        [ 4.71824050e-01, -3.82196844e-01,  5.72618246e-01, ...,\n",
            "         -5.27210653e-01,  1.42559096e-01, -4.82656777e-01],\n",
            "        ...,\n",
            "        [-2.15004534e-01, -2.77743012e-01, -1.45532608e-01, ...,\n",
            "         -2.47291878e-01, -1.64675727e-01, -7.98185915e-02],\n",
            "        [ 8.39286596e-02, -1.42898604e-01, -2.17353702e-01, ...,\n",
            "         -5.07279821e-02, -1.22659758e-01, -2.66682416e-01],\n",
            "        [ 4.75571863e-02, -1.75818890e-01, -1.63769662e-01, ...,\n",
            "         -8.60913396e-02, -1.26599446e-01, -2.75742829e-01]],\n",
            "\n",
            "       [[ 6.39851391e-01, -3.82861763e-01,  4.49819058e-01, ...,\n",
            "         -1.53656751e-01, -1.81384653e-01, -2.36746773e-01],\n",
            "        [ 7.78784215e-01, -6.58721924e-01,  4.84484494e-01, ...,\n",
            "          6.88545823e-01,  1.28693849e-01, -1.28041446e-01],\n",
            "        [ 6.31583095e-01, -5.59899926e-01,  5.65388441e-01, ...,\n",
            "          9.15184617e-01,  2.32980803e-01, -5.82145154e-01],\n",
            "        ...,\n",
            "        [-2.40692198e-01,  7.87435472e-02,  2.12905556e-01, ...,\n",
            "          5.21147966e-01, -2.48476937e-01, -1.46619901e-01],\n",
            "        [-1.85067102e-01, -4.01608527e-01,  1.27934843e-01, ...,\n",
            "          2.20544845e-01, -2.74412066e-01, -4.88337755e-01],\n",
            "        [ 2.29368191e-02,  7.08783139e-03, -2.22620144e-02, ...,\n",
            "         -2.95704715e-02,  6.16599014e-03, -2.27512326e-03]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 3.5386193e-01,  4.2432487e-01,  1.0331780e+00, ...,\n",
            "          1.1771723e+00,  1.7079201e-01, -2.8913534e-01],\n",
            "        [ 3.0118352e-01, -1.4615397e-01,  5.2545500e-01, ...,\n",
            "          1.2684773e+00, -1.4880641e-01, -1.8497369e-01],\n",
            "        [-1.6593084e-02,  1.6604128e-01,  5.7284975e-01, ...,\n",
            "          8.4167480e-01, -3.1970239e-01,  1.0910373e-01],\n",
            "        ...,\n",
            "        [ 2.8532007e-01,  2.5899222e-01,  5.4496717e-01, ...,\n",
            "          3.2691860e-01, -6.2701946e-01, -1.0331472e-01],\n",
            "        [ 2.7719802e-01,  3.0641255e-01,  4.7029537e-01, ...,\n",
            "          4.3967524e-01, -6.3062704e-01, -1.2106454e-01],\n",
            "        [ 2.1279556e-01,  3.0201474e-01,  5.8276665e-01, ...,\n",
            "          7.8021163e-01, -5.3237796e-01,  3.4811147e-02]],\n",
            "\n",
            "       [[ 4.5930994e-01,  2.9904535e-01,  5.4211342e-01, ...,\n",
            "          1.0284894e-01,  6.2580556e-01, -6.4315134e-01],\n",
            "        [-8.5265197e-02, -3.6101782e-01,  4.1678271e-01, ...,\n",
            "          7.9323131e-01, -3.7863010e-01, -1.2526511e-01],\n",
            "        [-1.3075000e-01, -3.4736037e-01,  4.9146287e-02, ...,\n",
            "          4.8192721e-02, -3.1020394e-01, -4.9795303e-01],\n",
            "        ...,\n",
            "        [ 6.3684571e-01,  2.6324716e-01,  7.8200960e-01, ...,\n",
            "          7.3986292e-01,  7.5809151e-02,  1.2674814e-01],\n",
            "        [ 4.4140217e-01,  3.1942174e-01,  8.4072113e-01, ...,\n",
            "          5.3103381e-01,  2.2232153e-01,  1.9543758e-01],\n",
            "        [ 3.1081936e-03,  6.4813904e-03, -4.7240391e-02, ...,\n",
            "         -9.1787584e-02, -6.2552476e-03,  1.9645863e-03]],\n",
            "\n",
            "       [[ 4.8474094e-01,  5.7086617e-01,  5.7674438e-01, ...,\n",
            "          1.0363798e-01,  3.3362108e-01, -7.0500642e-01],\n",
            "        [ 8.6283082e-01,  1.8122102e-01,  2.3161371e-01, ...,\n",
            "          3.8334501e-01, -1.0070215e-01, -2.5439399e-01],\n",
            "        [ 8.6118799e-01, -1.6692752e-01,  5.7857859e-01, ...,\n",
            "         -5.2324604e-02, -3.3720025e-01, -9.5441711e-01],\n",
            "        ...,\n",
            "        [ 6.0246176e-01,  9.2889839e-01,  4.0286955e-01, ...,\n",
            "          3.5730860e-01, -5.5537570e-01,  9.9885739e-02],\n",
            "        [ 5.9346682e-01,  7.2339118e-01,  3.2468402e-01, ...,\n",
            "          3.2368428e-01, -2.5287485e-01, -3.0307898e-02],\n",
            "        [ 4.7610402e-01,  7.0085984e-01,  2.9407325e-01, ...,\n",
            "          3.2861568e-03, -1.9665457e-01, -5.4301219e-03]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 3.1947961e-01, -1.9890092e-01,  3.1205398e-01, ...,\n",
            "          2.7817464e-01, -3.4932968e-01,  1.9689511e-01],\n",
            "        [ 6.7563814e-01, -5.1383114e-01,  2.3840559e-01, ...,\n",
            "          7.1419978e-01, -5.1655841e-01, -3.5226679e-01],\n",
            "        [ 1.8421578e-01, -3.0078399e-01,  2.8360844e-01, ...,\n",
            "         -2.3087323e-01, -2.2004701e-01,  8.8712379e-02],\n",
            "        ...,\n",
            "        [ 9.2724785e-02, -1.3437797e-01,  7.0057213e-01, ...,\n",
            "         -3.9577416e-01,  4.3975960e-02, -2.9689574e-01],\n",
            "        [-8.6350456e-02, -8.8825217e-03,  5.5199575e-01, ...,\n",
            "         -2.0194349e-01, -3.6320481e-02, -6.2855639e-02],\n",
            "        [ 7.5416990e-02, -5.1756511e-03,  4.9205706e-01, ...,\n",
            "          3.0849418e-01, -5.1887915e-02,  9.2007801e-02]],\n",
            "\n",
            "       [[ 2.3665082e-01,  5.5321477e-02,  2.4057421e-01, ...,\n",
            "          1.2093800e-01, -3.2084453e-01, -6.6257823e-01],\n",
            "        [-1.5189871e-01, -1.5884839e-01,  4.8312971e-01, ...,\n",
            "          1.6247783e-02, -1.5536444e-01, -1.9887550e-01],\n",
            "        [-1.1196609e-01,  5.5487774e-02,  4.7235692e-01, ...,\n",
            "         -1.7100859e-01, -6.0055103e-02, -5.9931678e-01],\n",
            "        ...,\n",
            "        [-4.0304345e-01, -9.5861085e-02,  2.3118678e-01, ...,\n",
            "          6.8251856e-02, -1.7328411e-01, -5.4920030e-01],\n",
            "        [-2.2695155e-01, -1.3669661e-01,  3.3021113e-01, ...,\n",
            "          2.2361486e-01, -2.2320560e-01, -4.7913170e-01],\n",
            "        [-2.4545132e-01, -1.2223440e-01,  3.5800880e-01, ...,\n",
            "          1.9197020e-01, -2.2147638e-01, -5.2173138e-01]],\n",
            "\n",
            "       [[ 6.7374623e-01, -1.9673221e-01,  4.4938111e-01, ...,\n",
            "          8.5324712e-02,  3.2502063e-02, -6.7180061e-01],\n",
            "        [ 7.2105449e-01, -6.3576770e-01,  4.7636926e-01, ...,\n",
            "          9.1563046e-01,  1.3065183e-01, -1.2894100e-01],\n",
            "        [ 5.6436515e-01, -7.0024842e-01,  7.2934234e-01, ...,\n",
            "          9.4361210e-01,  3.2360759e-01, -3.0869931e-01],\n",
            "        ...,\n",
            "        [ 4.5995656e-02, -2.1220246e-01,  1.0188340e+00, ...,\n",
            "          9.6618319e-01, -7.2961524e-02, -8.7361884e-01],\n",
            "        [ 3.2495287e-01, -1.6265246e-01,  5.9792346e-01, ...,\n",
            "          5.0128293e-01, -8.0239162e-02, -7.9731852e-01],\n",
            "        [ 2.5859405e-03,  6.4205378e-04, -4.3298319e-02, ...,\n",
            "         -7.4837498e-02, -7.7518960e-03,  6.0069980e-03]]], dtype=float32)>, <tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 0.48999685,  0.30394557,  1.0887244 , ...,  1.848758  ,\n",
            "          0.16467124, -0.325687  ],\n",
            "        [ 0.6065986 , -0.47776282,  0.2609226 , ...,  2.3007226 ,\n",
            "         -0.37581712, -0.05384592],\n",
            "        [ 0.17835021,  0.0432563 ,  0.5358286 , ...,  1.7011096 ,\n",
            "         -0.8225711 , -0.31128657],\n",
            "        ...,\n",
            "        [ 0.43941948, -0.10472678,  0.25476974, ...,  0.20237815,\n",
            "         -1.5171121 , -0.19064765],\n",
            "        [ 0.40880308, -0.03057112,  0.18960914, ...,  0.33230606,\n",
            "         -1.4877667 , -0.24122515],\n",
            "        [ 0.43330383, -0.03020421,  0.3457478 , ...,  0.81084216,\n",
            "         -1.2333322 , -0.07721795]],\n",
            "\n",
            "       [[ 0.99987936,  1.2835779 ,  0.02388676, ...,  0.9977577 ,\n",
            "          1.2500854 , -1.1794062 ],\n",
            "        [ 0.26703987, -0.0885807 , -0.29914248, ...,  1.657746  ,\n",
            "         -0.28823203, -0.9863708 ],\n",
            "        [ 0.4737345 ,  0.08817421, -0.7662977 , ...,  0.9803646 ,\n",
            "          0.11439648, -1.4191899 ],\n",
            "        ...,\n",
            "        [ 1.2971789 ,  0.16397429,  0.3485825 , ...,  1.9119446 ,\n",
            "          0.46491724, -0.3197778 ],\n",
            "        [ 0.773968  ,  0.48457286,  0.6620712 , ...,  1.4452722 ,\n",
            "          0.47040808, -0.31786555],\n",
            "        [ 0.6024262 ,  0.8948891 , -0.88424575, ...,  0.33295885,\n",
            "          0.03882322, -1.2961175 ]],\n",
            "\n",
            "       [[ 1.1740991 ,  1.7116408 , -0.62771875, ...,  0.12011175,\n",
            "          0.5876198 , -0.43853286],\n",
            "        [ 1.9617753 ,  1.0597332 , -0.6329293 , ..., -0.07484791,\n",
            "         -0.43435627, -0.27714744],\n",
            "        [ 1.7527653 ,  0.21749367, -0.8663637 , ..., -0.03038928,\n",
            "         -0.89147615, -1.4456551 ],\n",
            "        ...,\n",
            "        [ 0.80073154,  1.9420271 , -0.7931256 , ...,  0.5301756 ,\n",
            "         -0.5051745 ,  0.04461377],\n",
            "        [ 0.8580037 ,  1.6848023 , -0.9019501 , ...,  0.34428033,\n",
            "         -0.01970193, -0.15111127],\n",
            "        [ 0.6883769 ,  1.7651851 , -1.1083548 , ..., -0.02340291,\n",
            "          0.03038681, -0.06404908]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0.96673244, -0.9757073 , -0.6729101 , ...,  0.10245714,\n",
            "         -1.4360018 ,  0.6368365 ],\n",
            "        [ 1.0212293 , -1.202336  , -0.82417905, ...,  0.48489013,\n",
            "         -1.386378  ,  0.05813893],\n",
            "        [ 0.7505642 , -1.2743977 , -0.5657438 , ..., -0.3515046 ,\n",
            "         -1.211461  ,  0.19933295],\n",
            "        ...,\n",
            "        [ 0.38543457, -0.4752069 ,  0.09559022, ..., -1.1248261 ,\n",
            "         -0.7475004 , -0.08899341],\n",
            "        [ 0.22864296, -0.39244926, -0.05849198, ..., -0.63876927,\n",
            "         -0.66748285,  0.01125637],\n",
            "        [ 0.20374191, -0.24310406,  0.02054515, ...,  0.0282384 ,\n",
            "         -0.84229684,  0.09736294]],\n",
            "\n",
            "       [[ 0.61681485, -0.64683115,  0.05542181, ..., -0.14923872,\n",
            "         -1.4737661 , -1.1358342 ],\n",
            "        [ 0.6780807 , -0.30577207,  0.9188303 , ..., -0.17162772,\n",
            "         -1.0102537 , -0.7989334 ],\n",
            "        [ 0.5356299 , -0.24932896,  0.8462339 , ..., -0.2965466 ,\n",
            "         -0.9192232 , -1.0168628 ],\n",
            "        ...,\n",
            "        [ 0.11780452, -1.0960041 ,  0.0224838 , ..., -0.48648515,\n",
            "         -1.3867471 , -1.5836525 ],\n",
            "        [ 0.22272304, -1.1384673 ,  0.22708082, ..., -0.27952945,\n",
            "         -1.4431356 , -1.5419923 ],\n",
            "        [ 0.19411448, -1.1139201 ,  0.2417084 , ..., -0.30651832,\n",
            "         -1.4136612 , -1.5893302 ]],\n",
            "\n",
            "       [[ 1.372097  , -0.9079812 ,  0.51443446, ...,  0.8746104 ,\n",
            "         -0.56140685, -1.2453563 ],\n",
            "        [ 1.3533    , -0.75646365, -0.08431526, ...,  1.1709305 ,\n",
            "         -0.05924979, -0.6701156 ],\n",
            "        [ 1.4034362 , -0.8345915 ,  0.37453467, ...,  1.1732792 ,\n",
            "          0.42570427, -0.4023147 ],\n",
            "        ...,\n",
            "        [ 0.21145001, -0.57308316,  0.05205411, ...,  1.6949016 ,\n",
            "         -1.1161444 , -1.2461727 ],\n",
            "        [ 0.81271654, -0.46684772, -0.23421058, ...,  1.3180391 ,\n",
            "         -1.137247  , -1.4939287 ],\n",
            "        [ 0.88249385, -0.8316563 , -0.70794845, ...,  0.18275635,\n",
            "         -0.85935867, -1.2435668 ]]], dtype=float32)>], 'sequence_output': <tf.Tensor: shape=(500, 128, 768), dtype=float32, numpy=\n",
            "array([[[ 0.48999685,  0.30394557,  1.0887244 , ...,  1.848758  ,\n",
            "          0.16467124, -0.325687  ],\n",
            "        [ 0.6065986 , -0.47776282,  0.2609226 , ...,  2.3007226 ,\n",
            "         -0.37581712, -0.05384592],\n",
            "        [ 0.17835021,  0.0432563 ,  0.5358286 , ...,  1.7011096 ,\n",
            "         -0.8225711 , -0.31128657],\n",
            "        ...,\n",
            "        [ 0.43941948, -0.10472678,  0.25476974, ...,  0.20237815,\n",
            "         -1.5171121 , -0.19064765],\n",
            "        [ 0.40880308, -0.03057112,  0.18960914, ...,  0.33230606,\n",
            "         -1.4877667 , -0.24122515],\n",
            "        [ 0.43330383, -0.03020421,  0.3457478 , ...,  0.81084216,\n",
            "         -1.2333322 , -0.07721795]],\n",
            "\n",
            "       [[ 0.99987936,  1.2835779 ,  0.02388676, ...,  0.9977577 ,\n",
            "          1.2500854 , -1.1794062 ],\n",
            "        [ 0.26703987, -0.0885807 , -0.29914248, ...,  1.657746  ,\n",
            "         -0.28823203, -0.9863708 ],\n",
            "        [ 0.4737345 ,  0.08817421, -0.7662977 , ...,  0.9803646 ,\n",
            "          0.11439648, -1.4191899 ],\n",
            "        ...,\n",
            "        [ 1.2971789 ,  0.16397429,  0.3485825 , ...,  1.9119446 ,\n",
            "          0.46491724, -0.3197778 ],\n",
            "        [ 0.773968  ,  0.48457286,  0.6620712 , ...,  1.4452722 ,\n",
            "          0.47040808, -0.31786555],\n",
            "        [ 0.6024262 ,  0.8948891 , -0.88424575, ...,  0.33295885,\n",
            "          0.03882322, -1.2961175 ]],\n",
            "\n",
            "       [[ 1.1740991 ,  1.7116408 , -0.62771875, ...,  0.12011175,\n",
            "          0.5876198 , -0.43853286],\n",
            "        [ 1.9617753 ,  1.0597332 , -0.6329293 , ..., -0.07484791,\n",
            "         -0.43435627, -0.27714744],\n",
            "        [ 1.7527653 ,  0.21749367, -0.8663637 , ..., -0.03038928,\n",
            "         -0.89147615, -1.4456551 ],\n",
            "        ...,\n",
            "        [ 0.80073154,  1.9420271 , -0.7931256 , ...,  0.5301756 ,\n",
            "         -0.5051745 ,  0.04461377],\n",
            "        [ 0.8580037 ,  1.6848023 , -0.9019501 , ...,  0.34428033,\n",
            "         -0.01970193, -0.15111127],\n",
            "        [ 0.6883769 ,  1.7651851 , -1.1083548 , ..., -0.02340291,\n",
            "          0.03038681, -0.06404908]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0.96673244, -0.9757073 , -0.6729101 , ...,  0.10245714,\n",
            "         -1.4360018 ,  0.6368365 ],\n",
            "        [ 1.0212293 , -1.202336  , -0.82417905, ...,  0.48489013,\n",
            "         -1.386378  ,  0.05813893],\n",
            "        [ 0.7505642 , -1.2743977 , -0.5657438 , ..., -0.3515046 ,\n",
            "         -1.211461  ,  0.19933295],\n",
            "        ...,\n",
            "        [ 0.38543457, -0.4752069 ,  0.09559022, ..., -1.1248261 ,\n",
            "         -0.7475004 , -0.08899341],\n",
            "        [ 0.22864296, -0.39244926, -0.05849198, ..., -0.63876927,\n",
            "         -0.66748285,  0.01125637],\n",
            "        [ 0.20374191, -0.24310406,  0.02054515, ...,  0.0282384 ,\n",
            "         -0.84229684,  0.09736294]],\n",
            "\n",
            "       [[ 0.61681485, -0.64683115,  0.05542181, ..., -0.14923872,\n",
            "         -1.4737661 , -1.1358342 ],\n",
            "        [ 0.6780807 , -0.30577207,  0.9188303 , ..., -0.17162772,\n",
            "         -1.0102537 , -0.7989334 ],\n",
            "        [ 0.5356299 , -0.24932896,  0.8462339 , ..., -0.2965466 ,\n",
            "         -0.9192232 , -1.0168628 ],\n",
            "        ...,\n",
            "        [ 0.11780452, -1.0960041 ,  0.0224838 , ..., -0.48648515,\n",
            "         -1.3867471 , -1.5836525 ],\n",
            "        [ 0.22272304, -1.1384673 ,  0.22708082, ..., -0.27952945,\n",
            "         -1.4431356 , -1.5419923 ],\n",
            "        [ 0.19411448, -1.1139201 ,  0.2417084 , ..., -0.30651832,\n",
            "         -1.4136612 , -1.5893302 ]],\n",
            "\n",
            "       [[ 1.372097  , -0.9079812 ,  0.51443446, ...,  0.8746104 ,\n",
            "         -0.56140685, -1.2453563 ],\n",
            "        [ 1.3533    , -0.75646365, -0.08431526, ...,  1.1709305 ,\n",
            "         -0.05924979, -0.6701156 ],\n",
            "        [ 1.4034362 , -0.8345915 ,  0.37453467, ...,  1.1732792 ,\n",
            "          0.42570427, -0.4023147 ],\n",
            "        ...,\n",
            "        [ 0.21145001, -0.57308316,  0.05205411, ...,  1.6949016 ,\n",
            "         -1.1161444 , -1.2461727 ],\n",
            "        [ 0.81271654, -0.46684772, -0.23421058, ...,  1.3180391 ,\n",
            "         -1.137247  , -1.4939287 ],\n",
            "        [ 0.88249385, -0.8316563 , -0.70794845, ...,  0.18275635,\n",
            "         -0.85935867, -1.2435668 ]]], dtype=float32)>, 'default': <tf.Tensor: shape=(500, 768), dtype=float32, numpy=\n",
            "array([[ 0.45421395,  0.2949192 ,  0.79641217, ...,  0.95162886,\n",
            "         0.16319875, -0.31464005],\n",
            "       [ 0.76154345,  0.8574352 ,  0.02388221, ...,  0.7606509 ,\n",
            "         0.8483076 , -0.82726425],\n",
            "       [ 0.8255818 ,  0.9368485 , -0.5564794 , ...,  0.11953744,\n",
            "         0.5281816 , -0.41242757],\n",
            "       ...,\n",
            "       [ 0.74726486, -0.7512017 , -0.58689094, ...,  0.10210011,\n",
            "        -0.8928899 ,  0.56274176],\n",
            "       [ 0.54890645, -0.5695328 ,  0.05536514, ..., -0.14814052,\n",
            "        -0.9002934 , -0.8130065 ],\n",
            "       [ 0.8791692 , -0.72016203,  0.47339314, ...,  0.7037091 ,\n",
            "        -0.5090205 , -0.8469763 ]], dtype=float32)>, 'pooled_output': <tf.Tensor: shape=(500, 768), dtype=float32, numpy=\n",
            "array([[ 0.45421395,  0.2949192 ,  0.79641217, ...,  0.95162886,\n",
            "         0.16319875, -0.31464005],\n",
            "       [ 0.76154345,  0.8574352 ,  0.02388221, ...,  0.7606509 ,\n",
            "         0.8483076 , -0.82726425],\n",
            "       [ 0.8255818 ,  0.9368485 , -0.5564794 , ...,  0.11953744,\n",
            "         0.5281816 , -0.41242757],\n",
            "       ...,\n",
            "       [ 0.74726486, -0.7512017 , -0.58689094, ...,  0.10210011,\n",
            "        -0.8928899 ,  0.56274176],\n",
            "       [ 0.54890645, -0.5695328 ,  0.05536514, ..., -0.14814052,\n",
            "        -0.9002934 , -0.8130065 ],\n",
            "       [ 0.8791692 , -0.72016203,  0.47339314, ...,  0.7037091 ,\n",
            "        -0.5090205 , -0.8469763 ]], dtype=float32)>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d_gpKPhuQEG",
        "outputId": "23bb6a32-11f2-4a50-9965-38d7d23dc0ff"
      },
      "source": [
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pooled Outputs Shape:(500, 768)\n",
            "Pooled Outputs Values:[ 0.45421395  0.2949192   0.79641217  0.60480106  0.3280845   0.03076395\n",
            " -0.28662452 -0.61797523  0.7500393   0.03723879  0.5965795  -0.54139286]\n",
            "Sequence Outputs Shape:(500, 128, 768)\n",
            "Sequence Outputs Values:[[ 0.48999685  0.30394557  1.0887244  ...  1.848758    0.16467124\n",
            "  -0.325687  ]\n",
            " [ 0.6065986  -0.47776282  0.2609226  ...  2.3007226  -0.37581712\n",
            "  -0.05384592]\n",
            " [ 0.17835021  0.0432563   0.5358286  ...  1.7011096  -0.8225711\n",
            "  -0.31128657]\n",
            " ...\n",
            " [ 0.44960898  0.07259469  0.03648981 ...  0.00718453 -1.6866527\n",
            "  -0.32370418]\n",
            " [ 0.46865958 -0.03646746  0.08884454 ...  0.01199529 -1.8194145\n",
            "  -0.43946   ]\n",
            " [ 0.44177595 -0.06479785  0.04875329 ...  0.06126611 -1.7820753\n",
            "  -0.42757037]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZvV7Gp5HcN9"
      },
      "source": [
        "Create classifier model using transformer layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3oI0MxVvmwi"
      },
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, GRU, Embedding\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(vocab_size, 100))\n",
        "# model.add(GRU(128))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "# history = model.fit(x_train, y_train, epochs=15, batch_size=60, validation_split=0.2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "S4rG7TdWG59c",
        "outputId": "2d00d5ed-98cd-42db-f810-f0dcdee8e1d2"
      },
      "source": [
        "embed_dim = 768  # Embedding size for each token\n",
        "num_heads = 3  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "x = layers.Input(shape=(128,768))\n",
        "# embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "# x = embedding_layer(x)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)  #출력층은 3개 여야지\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7e1d80b28a2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#출력층은 3개 여야지\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_graph_inputs_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# A Network does not create weights of its own, thus it is already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_validate_graph_inputs_and_outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    689\u001b[0m                          \u001b[0;34m'must come from `tf.keras.Input`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m                          \u001b[0;34m'Received: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m                          ' (missing previous layer metadata).')\n\u001b[0m\u001b[1;32m    692\u001b[0m       \u001b[0;31m# Check that x is an input tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input tensors to a Functional must come from `tf.keras.Input`. Received: tf.Tensor(\n[[1 1 1 ... 0 0 0]\n [1 1 1 ... 1 1 1]\n [1 1 1 ... 0 0 0]\n ...\n [1 1 1 ... 0 0 0]\n [1 1 1 ... 0 0 0]\n [1 1 1 ... 1 1 1]], shape=(500, 128), dtype=int32) (missing previous layer metadata)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "ZrulowwGHFCg",
        "outputId": "102e5524-4236-4993-cfa6-1fb8ba8d7782"
      },
      "source": [
        "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(\n",
        "    x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-aae832f6e26a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhamoh1mHFFs"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Fit the model\n",
        "results = history\n",
        "# list all data in history\n",
        "print(results.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(results.history['accuracy'])\n",
        "plt.plot(results.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(results.history['loss'])\n",
        "plt.plot(results.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLZBq9wzHFNS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--QxOxdkHFPp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}