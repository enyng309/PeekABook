{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_NER.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxlC8O0GoZMYgN7cycCnfj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seawavve/PeekABook/blob/main/NER/Spark_NER_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkgKe3_DpEQW"
      },
      "source": [
        "# 환경설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae7PAh_Z0XZA",
        "outputId": "6c3515b5-901d-4180-83b7-bac37ad2d3a9"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-08 10:56:58--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-07-08 10:56:58--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                     0%[                    ]       0  --.-KB/s               setup Colab for PySpark 3.0.3 and Spark NLP 3.1.2\n",
            "-                   100%[===================>]   1.57K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-07-08 10:56:59 (1.94 MB/s) - written to stdout [1608/1608]\n",
            "\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,221 kB]\n",
            "Ign:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [637 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,188 kB]\n",
            "Hit:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,780 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,418 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,658 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [910 kB]\n",
            "Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n",
            "Fetched 12.1 MB in 7s (1,720 kB/s)\n",
            "Reading package lists... Done\n",
            "\u001b[K     |████████████████████████████████| 209.1MB 59kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 46.3MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tINf3SZP0Nzy"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "def get_ann_pipeline ():\n",
        "    \n",
        "    document_assembler = DocumentAssembler() \\\n",
        "        .setInputCol(\"text\")\\\n",
        "        .setOutputCol('document')\n",
        "\n",
        "    sentence = SentenceDetector()\\\n",
        "        .setInputCols(['document'])\\\n",
        "        .setOutputCol('sentence')\\\n",
        "        .setCustomBounds(['\\n'])\n",
        "\n",
        "    tokenizer = Tokenizer() \\\n",
        "        .setInputCols([\"sentence\"]) \\\n",
        "        .setOutputCol(\"token\")\n",
        "\n",
        "    pos = PerceptronModel.pretrained() \\\n",
        "              .setInputCols([\"sentence\", \"token\"]) \\\n",
        "              .setOutputCol(\"pos\")\n",
        "    \n",
        "    embeddings = WordEmbeddingsModel.pretrained()\\\n",
        "          .setInputCols([\"sentence\", \"token\"])\\\n",
        "          .setOutputCol(\"embeddings\")\n",
        "\n",
        "    ner_model = NerDLModel.pretrained() \\\n",
        "          .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "          .setOutputCol(\"ner\")\n",
        "\n",
        "    ner_converter = NerConverter()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "      .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "    ner_pipeline = Pipeline(\n",
        "        stages = [\n",
        "            document_assembler,\n",
        "            sentence,\n",
        "            tokenizer,\n",
        "            pos,\n",
        "            embeddings,\n",
        "            ner_model,\n",
        "            ner_converter\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "    ner_pipelineFit = ner_pipeline.fit(empty_data)\n",
        "\n",
        "    ner_lp_pipeline = LightPipeline(ner_pipelineFit)\n",
        "\n",
        "    print (\"Spark NLP NER lightpipeline is created\")\n",
        "\n",
        "    return ner_lp_pipeline\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3L5-lUp0OuA",
        "outputId": "0e13a4af-9b8e-4b41-c9b8-e80f641f6393"
      },
      "source": [
        "conll_pipeline = get_ann_pipeline ()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos_anc download started this may take some time.\n",
            "Approximate size to download 3.9 MB\n",
            "[OK!]\n",
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "ner_dl download started this may take some time.\n",
            "Approximate size to download 13.6 MB\n",
            "[OK!]\n",
            "Spark NLP NER lightpipeline is created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrd8-VgypNbv"
      },
      "source": [
        "# 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1KRI-XQ0Owv",
        "outputId": "3773b21b-ca43-4e63-fc32-d4d108dfc864"
      },
      "source": [
        "parsed = conll_pipeline.annotate (\"Peter Parker Baker is in a baby blue Cadillac.\")\n",
        "\n",
        "for key in parsed.keys():\n",
        "    print(key,': ',parsed[key])\n",
        "    \n",
        "#parsed"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "document :  ['Peter Parker Baker is in a baby blue Cadillac.']\n",
            "ner_chunk :  ['Peter Parker Baker', 'Cadillac']\n",
            "pos :  ['NNP', 'NNP', 'NNP', 'VBZ', 'IN', 'DT', 'NN', 'JJ', 'NNP', '.']\n",
            "token :  ['Peter', 'Parker', 'Baker', 'is', 'in', 'a', 'baby', 'blue', 'Cadillac', '.']\n",
            "ner :  ['B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O']\n",
            "embeddings :  ['Peter', 'Parker', 'Baker', 'is', 'in', 'a', 'baby', 'blue', 'Cadillac', '.']\n",
            "sentence :  ['Peter Parker Baker is in a baby blue Cadillac.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHRU2OEM0Oz8",
        "outputId": "461a363a-933a-436b-c6e7-4e001bb69fed"
      },
      "source": [
        "conll_lines=''\n",
        "\n",
        "for token, pos, ner in zip(parsed['token'],parsed['pos'],parsed['ner']):\n",
        "\n",
        "    conll_lines += \"{} {} {} {}\\n\".format(token, pos, pos, ner)\n",
        "\n",
        "\n",
        "print(conll_lines)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Peter NNP NNP B-PER\n",
            "Parker NNP NNP I-PER\n",
            "Baker NNP NNP I-PER\n",
            "is VBZ VBZ O\n",
            "in IN IN O\n",
            "a DT DT O\n",
            "baby NN NN O\n",
            "blue JJ JJ O\n",
            "Cadillac NNP NNP B-ORG\n",
            ". . . O\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_DB67Dy1vaG",
        "outputId": "62d6ca12-f786-4368-dc6a-ff0a7a46201f"
      },
      "source": [
        "sentences=['Peter Parker Baker is in a baby blue Cadillac.','I love you.','Hanhee fell a sleep']\n",
        "\n",
        "def get_person_entity(sentences):\n",
        "  data=[]\n",
        "  for sentence in sentences:\n",
        "    parsed = conll_pipeline.annotate (sentence)\n",
        "    line_entity=[]\n",
        "\n",
        "    if 'B-PER' in parsed['ner']:\n",
        "      for i in range(len(parsed['ner'])):\n",
        "        if parsed['ner'][i]=='B-PER':\n",
        "          name=parsed['embeddings'][i]\n",
        "          line_entity.append(name)\n",
        "        elif parsed['ner'][i]=='I-PER':\n",
        "          line_entity[-1]+=' '+parsed['embeddings'][i]\n",
        "      data.append(line_entity)\n",
        "    else:\n",
        "      data.append(line_entity)\n",
        "      \n",
        "  return data\n",
        "\n",
        "print(get_person_entity(sentences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Peter Parker Baker'], [], ['Hanhee']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "iupFqBAH0GQt",
        "outputId": "45d85a3a-5231-48c9-93db-82f83c1182b0"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('Predicted_result.csv')\n",
        "df['person']=get_person_entity(df['sentence'])\n",
        "display(df)\n",
        "df.to_csv('Entity_Predicted_result.csv')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentence</th>\n",
              "      <th>mark</th>\n",
              "      <th>predicted_mark</th>\n",
              "      <th>person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b' He ended by imploring Zobeida not to confou...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>[Zobeida]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b' Is this, continued Zobeida, growing more an...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[Zobeida]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b' But I am very angry with your brothers, and...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b' Both I and my subjects esteem you, and wish...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b' The Sultan was so delighted to hear these w...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Sultan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>167</td>\n",
              "      <td>b' He was delighted.'</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>168</td>\n",
              "      <td>b' But no, it will be better if I throw you in...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>169</td>\n",
              "      <td>b' To his great surprise, he heard her saying ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Rejoice]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>170</td>\n",
              "      <td>b' When he arrived home his wife and children ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>171</td>\n",
              "      <td>b' Rejoice, he said, your cruel enemy is dead.'</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Rejoice]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>172 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ...     person\n",
              "0             0  ...  [Zobeida]\n",
              "1             1  ...  [Zobeida]\n",
              "2             2  ...         []\n",
              "3             3  ...         []\n",
              "4             4  ...   [Sultan]\n",
              "..          ...  ...        ...\n",
              "167         167  ...         []\n",
              "168         168  ...         []\n",
              "169         169  ...  [Rejoice]\n",
              "170         170  ...         []\n",
              "171         171  ...  [Rejoice]\n",
              "\n",
              "[172 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}